{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1\n",
    "# how to load pyspark delta table to pnr_df dataframe \n",
    "pnr_df = spark.read.format(\"delta\").load(\"path/to/delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt 2 \n",
    "#create a new dataframe joined_df by Joining pnr_df and distance_master_df on following conditionsl (ORIG_AP_CD = airport_origin_code AND DESTN_AP_CD = airport_destination_code) OR (ORIG_AP_CD = airport_destination_code AND DESTN_AP_CD = airport_origin_code\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "    Joined_df = pnr_df.join(distance_master_df, (\n",
    "        ((col(\"ORIG_AP_CD\") == col(\"airport_origin_code\")) & (col(\"DESTN_AP_CD\") == col(\"airport_destination_code\"))) |\n",
    "        ((col(\"ORIG_AP_CD\") == col(\"airport_destination_code\")) & (col(\"DESTN_AP_CD\") == col(\"airport_origin_code\"))))\n",
    "        , how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 3\n",
    "# create a new dataframe joined_df by Joining Joined_df and location_master_df on following conditionsl (ORIG_AP_CD = ap_cd_val) OR (DESTN_AP_CD = ap_cd_val)\n",
    "Joined_df = Joined_df.join(location_master_df, col(\"ORIG_AP_CD\") == col(\"ap_cd_val\"), how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 4 \n",
    "# rename the columns ap_cd_val, latitude and longitude to ap_cd_val_origin, latitude_origin and longitude_origin\n",
    "\n",
    "newJoined_df=Joined_df.withColumnRenamed(\"ap_cd_val\",\"ap_cd_val_origin\") \\\n",
    ".withColumnRenamed(\"latitude\",\"latitude_origin\") \\\n",
    ".withColumnRenamed(\"longitude\",\"longitude_origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 5\n",
    "# rename the columns ap_cd_val, latitude and longitude to ap_cd_val_destination, latitude_destination and longitude_destination\n",
    "\n",
    "new_Joined_df = new_Joined_df.join(location_master_df, col(\"DESTN_AP_CD\") == col(\"ap_cd_val\"), how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 6\n",
    "# rename the columns ap_cd_val, latitude and longitude to ap_cd_val_desti, latitude_desti and longitude_desti\n",
    "# rename the column distance_in_km to distance_in_km_OD\n",
    "# rename the column id to id_OD\n",
    "\n",
    "new_Joined_df = new_Joined_df.withColumnRenamed(\"ap_cd_val\", \"ap_cd_val_desti\") \\\n",
    "    .withColumnRenamed(\"latitude\", \"latitude_desti\") \\\n",
    "    .withColumnRenamed(\"longitude\", \"longitude_desti\") \\\n",
    "    .withColumnRenamed(\"distance_in_km\", \"distance_in_km_OD\") \\\n",
    "    .withColumnRenamed(\"id\", \"id_OD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 7\n",
    "# Create a Pyspark UDF to convert DMS to Decimal degress ( copilot prompt 7)\n",
    "# This udf should take one parameter DMS, it should calculates the decimal degrees based on degrees, minutes, seconds, direction values and returns the result. If the direction is either 'S' or 'W', it negates the result because these directions represent negative values in the coordinate system.\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def dms_to_decimal(degrees, minutes, seconds, direction):\n",
    "    decimal_degrees = degrees + (minutes / 60) + (seconds / 3600)\n",
    "    if direction in ['S', 'W']:\n",
    "        decimal_degrees = -decimal_degrees\n",
    "    return decimal_degrees\n",
    "\n",
    "dms_to_decimal_udf = udf(dms_to_decimal, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#prompt 8\n",
    "#Apply the UDF to all the latitude and longitude columns\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Apply the UDF to the latitude and longitude columns\n",
    "new_Joined_df = new_Joined_df.withColumn(\"latitude_origin\", dms_to_decimal_udf(col(\"latitude_origin\")))\n",
    "new_Joined_df = new_Joined_df.withColumn(\"longitude_origin\", dms_to_decimal_udf(col(\"longitude_origin\")))\n",
    "new_Joined_df = new_Joined_df.withColumn(\"latitude_desti\", dms_to_decimal_udf(col(\"latitude_desti\")))\n",
    "new_Joined_df = new_Joined_df.withColumn(\"longitude_desti\", dms_to_decimal_udf(col(\"longitude_desti\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 9\n",
    "# Write a Python UDF to calculate the distance between two points using their latitude and longitude. The UDF accept the latitude and longitude for both points and return the distance in kilometers using the Haversine formula.\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon1 = math.radians(lon1)\n",
    "    lat2 = math.radians(lat2)\n",
    "    lon2 = math.radians(lon2)\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    distance = 6371 * c  # Radius of the Earth in kilometers\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
